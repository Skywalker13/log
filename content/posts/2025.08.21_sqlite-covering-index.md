---
title: 'SQLite et les "covering indices" ~ ðŸ‡«ðŸ‡· â€¢ ðŸ‡¬ðŸ‡§'
date: 2025-08-21
tags: [sqlite]
description: "ou les index couvrants"
draft: false
---

**Â» FRANÃ‡AIS | [ENGLISH](/en/2025.08.21_sqlite-covering-index/)**

---

- [Une table ordinaire](/posts/2025.08.21_sqlite-covering-index/#une-table-ordinaire)
- [Une requÃªte ordinaire](/posts/2025.08.21_sqlite-covering-index/#une-requÃªte-ordinaire)
  - [VÃ©rifions ce que je vous raconte](/posts/2025.08.21_sqlite-covering-index/#vÃ©rifions-ce-que-je-vous-raconte)
  - [Performances de la requÃªte](/posts/2025.08.21_sqlite-covering-index/#performances-de-la-requÃªte)
- [Mais que se passe-t-il ?](/posts/2025.08.21_sqlite-covering-index/#mais-que-se-passe-t-il-)
- [Le mystÃ¨re rÃ©solu](/posts/2025.08.21_sqlite-covering-index/#le-mystÃ¨re-rÃ©solu)
- [Conclusion](/posts/2025.08.21_sqlite-covering-index/#conclusion)

---

J'ai dÃ©couvert tout rÃ©cemment une optimisation un peu Ã©tonnante que l'on peut
faire avec [SQLite][5]. Mais tout d'abord, qu'est-ce qu'un index couvrant (ou
[covering index][4]) ? C'est un index qui contient toutes les colonnes
nÃ©cessaires pour rÃ©pondre Ã  la requÃªte sans que le moteur SQL ait besoin
d'accÃ©der Ã  la table. Cela permet Ã©videmment d'Ã©conomiser du temps. Mais comme
pour tout index, on va en perdre Ã  l'insertion, pour autant qu'on considÃ¨re que
c'est significatif pour notre application, ce qui n'est pas un problÃ¨me dans mon
cas.

## Une table ordinaire

Il n'y a rien de particulier Ã  avoir des index couvrants. Mais avant d'aller
plus loin, je vais vous prÃ©senter une table trÃ¨s simple comme vous pourriez en
voir dans de nombreux logiciels.

```sql
CREATE TABLE data (
  rowid     INTEGER PRIMARY KEY AUTOINCREMENT,
  timestamp TEXT,
  payload   JSON,
  commitId  TEXT DEFAULT NULL
);

CREATE INDEX commitId ON data (commitId);
```

Cette table a un index qui est la clef primaire `rowid` et auto-incrÃ©mentÃ©e. La
colonne `rowid` est spÃ©ciale dans SQLite car elle existe toujours mÃªme si on ne
la dÃ©clare pas explicitement dans le schÃ©ma et qu'on ne demande pas
explicitement une table sans `rowid` ([WITHOUT ROWID][1]).

Le but avec cette table est que le `rowid` ne soit [jamais recyclÃ©][6] en cas de
suppression de lignes. En ne dÃ©clarant pas explicitement une colonne
`INTEGER PRIMARY KEY` dans le schÃ©ma, il est tout Ã  fait possible qu'un `rowid`
soit rÃ©utilisÃ©. Pour notre usage ici, on va garantir que le `rowid` ne fait que
s'incrÃ©menter. Le `rowid` Ã©tant un [identifiant 64 bits][2] utilisÃ© au niveau du
stockage, ce n'est pas un index comme les autres. Les accÃ¨s aux donnÃ©es en se
basant sur le `rowid` sont bien plus rapides et optimisÃ©s qu'avec un index
ordinaire.

## Une requÃªte ordinaire

Voici une requÃªte nÃ©cessaire dans cette application. Celle-ci va compter combien
il y a de lignes avec un `rowid` plus grand que le plus grand `rowid` qui existe
pour un `commitId` donnÃ©. Il faut comprendre qu'un mÃªme `commitId` peut
apparaÃ®tre plusieurs fois dans la table ; d'ailleurs, ce n'est pas un index
unique.

```sql
SELECT count(*)
FROM data
WHERE rowid > (
  SELECT max(rowid)
  FROM data
  WHERE commitId = 'abcd'
);
```

Exemple avec quelques donnÃ©es :

| rowid | timestamp                | payload | commitId |     |
| ----- | ------------------------ | ------- | -------- | --- |
| 1     | 2025-08-21T09:52:11.245Z | {...}   | _abcd_   |     |
| 2     | 2025-08-21T09:52:11.245Z | {...}   | _abcd_   |     |
| 3     | 2025-08-21T09:52:11.245Z | {...}   | ef01     |     |
| 11    | 2025-08-21T09:52:11.245Z | {...}   | _abcd_   |     |
| 13    | 2025-08-21T09:52:11.245Z | {...}   | ef01     | x   |
| 14    | 2025-08-21T09:52:11.245Z | {...}   | 2345     | x   |

Pour le `commitId` `abcd`, la requÃªte va retourner la valeur 2 (les `rowid` 13
et 14 sont plus grands que le plus grand `rowid` utilisÃ© par le `commitId`
`abcd` qui vaut 11).

Je pense que comme moi, vous trouvez tout ceci assez simple et ordinaire. La
seule particularitÃ© de cette requÃªte c'est l'utilisation d'une sous-requÃªte pour
rÃ©cupÃ©rer le plus grand `rowid` associÃ© Ã  un `commitId`. Vous Ãªtes certainement
d'accord avec moi que Ã§a devrait Ãªtre assez efficace car la sous-requÃªte peut
exploiter l'index `commitId` pour rÃ©duire la quantitÃ© de donnÃ©es dans laquelle
retrouver le `max`. D'ailleurs, dans l'application, il n'y a que trÃ¨s rarement
beaucoup de lignes pour un mÃªme `commitId` (moins d'une dizaine).

### VÃ©rifions ce que je vous raconte

En utilisant `EXPLAIN QUERY PLAN` avec notre `SELECT ...` on va pouvoir vÃ©rifier
que je ne vous raconte pas de bÃªtises.

| id  | parent | detail                                                 |
| --- | ------ | ------------------------------------------------------ |
| 3   | 0      | SEARCH data USING INTEGER PRIMARY KEY (rowid>?)        |
| 6   | 0      | SCALAR SUBQUERY 1                                      |
| 11  | 6      | SEARCH data USING COVERING INDEX commitId (commitId=?) |

Ceci paraÃ®t trÃ¨s bien et mÃªme merveilleux. La sous-requÃªte utilise bien l'index
`commitId` et en plus en mode couvrant car on n'accÃ¨de Ã  rien d'autre qu'Ã 
l'index pour rÃ©soudre la condition `commitId = 'abcd'`. Concernant la condition
avec `rowid > (...)` on accÃ¨de Ã  l'index de la clef primaire. On peut imaginer
que c'est trÃ¨s performant car on utilise directement le `rowid` de la table de
SQLite.

### Performances de la requÃªte

Jetons alors un Å“il aux performances avec une table qui contient environ 200'000
lignes et un `commitId` qui se situe presque au milieu de celle-ci. Il n'y a que
3 lignes (avec la sous-requÃªte) pour ce `commitId`.

```
$ sqlite3 data.db
SQLite version 3.46.1 2024-08-13 09:16:08
Enter ".help" for usage hints.
sqlite> .timer on
sqlite> SELECT count(*)
FROM data
WHERE rowid > (
  SELECT max(rowid)
  FROM data
  WHERE commitId = '81b5f0ae-7f4a-4db2-ae3f-dea5bd35e0ad'
);
93356
Run Time: real 0.031 user 0.007897 sys 0.023278
sqlite> SELECT count(*) ...
93356
Run Time: real 0.038 user 0.007570 sys 0.030460
sqlite> SELECT count(*) ...
93356
Run Time: real 0.038 user 0.003727 sys 0.033857
sqlite> SELECT count(*) ...
93356
Run Time: real 0.033 user 0.011919 sys 0.020516
```

L'instruction `.timer on` permet d'activer un minuteur pour chaque requÃªte
exÃ©cutÃ©e. Voici ce qui en ressort :

|     | dÃ©lai |
| --- | ----- |
| 0   | 31 ms |
| 1   | 38 ms |
| 2   | 38 ms |
| 3   | 33 ms |

Je ne sais pas ce que vous en pensez, mais moi je ne suis pas satisfait du
rÃ©sultat. Je peux exÃ©cuter cette requÃªte des dizaines de fois, elle ne descend
jamais en dessous des 30 ms. Ne trouvez-vous pas que c'est un peu lent ? Il n'y
a pas tant de lignes que Ã§a, le schÃ©ma est simple, les requÃªtes sont simples, le
planificateur de requÃªtes est satisfait.

## Mais que se passe-t-il ?

C'est une excellente question et c'est tout le sujet de cet article. Il y a un
moyen d'amÃ©liorer drastiquement les performances de cette requÃªte. Voici une
mesure avec le changement que je vais vous prÃ©senter plus bas (ne sautez pas
directement Ã  la fin de l'article, essayez d'imaginer comment amÃ©liorer les
performances de ce `SELECT` en allant revoir le schÃ©ma et ce que le
planificateur de requÃªtes a dit).

```
$ sqlite3 data.db
SQLite version 3.46.1 2024-08-13 09:16:08
Enter ".help" for usage hints.
sqlite> .timer on
sqlite> SELECT count(*)
FROM data
WHERE rowid > (
  SELECT max(rowid)
  FROM data
  WHERE commitId = '81b5f0ae-7f4a-4db2-ae3f-dea5bd35e0ad'
);
93356
Run Time: real 0.002 user 0.000577 sys 0.001397
sqlite> SELECT count(*) ...
93356
Run Time: real 0.002 user 0.000456 sys 0.001106
sqlite> SELECT count(*) ...
93356
Run Time: real 0.005 user 0.004119 sys 0.000222
sqlite> SELECT count(*) ...
93356
Run Time: real 0.004 user 0.004134 sys 0.000268
```

---

|     | avant | aprÃ¨s |
| --- | ----- | ----- |
| 0   | 31 ms | 2 ms  |
| 1   | 38 ms | 2 ms  |
| 2   | 38 ms | 5 ms  |
| 3   | 33 ms | 4 ms  |

On passe de plus de 30 ms Ã  quelques millisecondes. Pour comprendre ce qui se
passe ici, il faut rÃ©Ã©tudier ce que le planificateur de requÃªtes nous a dit tout
Ã  l'heure et surtout la premiÃ¨re ligne
`SEARCH data USING INTEGER PRIMARY KEY (rowid>?)`. Ici il n'est pas dit que
SQLite va utiliser un index couvrant, mais uniquement que SQLite va utiliser
l'index sur la clef primaire. Mais finalement, qu'est-ce que Ã§a signifie dans ce
cas ?

Cette clef primaire n'est pas un index ordinaire car c'est l'identifiant qui
permet de retrouver un enregistrement dans la table. Ce qui veut dire qu'il faut
accÃ©der Ã  la table pour accÃ©der Ã  cette clef. C'est trÃ¨s performant si vous
voulez extraire un enregistrement de la table comme par exemple avec un simple
`SELECT * FROM data WHERE rowid = 101256;`. Un `SELECT` de ce type doit
forcÃ©ment aller chercher les donnÃ©es et il vaut mieux connaÃ®tre directement
l'identifiant et ne pas perdre de temps avec un index intermÃ©diaire.

Mais que faire pour le `SELECT count(*) ...` ? Il nous faut un index couvrant.
Ainsi SQLite ne va pas accÃ©der aux pages du stockage pour retrouver les `rowid`.
Ne pas accÃ©der au stockage permet d'Ã©viter le chargement des autres colonnes de
la table. Si vous regardez bien le schÃ©ma, il y a une colonne `payload`. Cette
colonne peut contenir de gros documents `JSON`. C'est une colonne assez lourde
et ici, elle est suffisante pour rendre la requÃªte moins efficace bien qu'on ne
s'intÃ©resse pas du tout au `payload`.

## Le mystÃ¨re rÃ©solu

```sql
CREATE INDEX rowId ON data (rowId);
```

OMG ?! ðŸ˜±

Nous sommes en train de crÃ©er un index par-dessus une clef primaire. Sommes-nous
devenus fous ? MÃªme le **Grand** [Richard Hipp][3] (auteur de SQLite) nous dit :

> **(2) By Richard Hipp (drh) on 2020-09-26 18:18:07 in reply to 1**
>
> An INTEGER PRIMARY KEY becomes the actual key used in the B-tree that stores
> your table. So no index is required for efficient operation.
>
> You should always omit indexes on PRIMARY KEY columns, regardless of the type.
> The best case for an index on a PRIMARY KEY is that it will be a no-op. The
> worst case is that it will make things run slower. So avoid the worst-case and
> just leave it off.
>
> -- https://sqlite.org/forum/info/8876e4e648bf8f93

Voyons voir ce que nous dit le planificateur de requÃªtes...

| id  | parent | detail                                                 |
| --- | ------ | ------------------------------------------------------ |
| 3   | 0      | SEARCH data USING COVERING INDEX rowId (rowid>?)       |
| 6   | 0      | SCALAR SUBQUERY 1                                      |
| 11  | 6      | SEARCH data USING COVERING INDEX commitId (commitId=?) |

DÃ©sormais c'est bien l'index couvrant qui est utilisÃ©. Nous sommes face alors Ã 
un cas de figure oÃ¹ ajouter un index par-dessus une clef primaire va amÃ©liorer
drastiquement les performances de ce `SELECT`.

Ã€ noter que si je supprime la colonne `payload` et que je reteste la requÃªte
sans l'index couvrant sur `rowid`, j'obtiens environ 9 ms au lieu de plus de 30
ms.

## Conclusion

Ce qu'il faut retenir c'est qu'avec un `INTEGER PRIMARY KEY`, SQLite doit
charger les pages complÃ¨tes (avec `payload`). Mais avec l'index couvrant
([covering index][4]), SQLite ne lit plus que l'index lÃ©ger.

Ces diffÃ©rentes expÃ©rimentations montrent une particularitÃ© peu connue du moteur
SQLite. On peut probablement considÃ©rer ce comportement comme un cas limite avec
des subtilitÃ©s entre l'optimiseur de requÃªtes, les index couvrants et les
opÃ©rations d'agrÃ©gation avec de gros volumes. Je ne vais pas vous conseiller de
le faire, mais je vous encourage Ã  inspecter et mesurer vos requÃªtes avec et
sans cet index qui semble pourtant mal venu.

[1]: https://sqlite.org/withoutrowid.html
[2]: https://sqlite.org/lang_createtable.html#rowid
[3]: https://en.wikipedia.org/wiki/D._Richard_Hipp
[4]: https://en.wikipedia.org/wiki/Database_index#Covering_index
[5]: https://sqlite.org
[6]: https://sqlite.org/lang_vacuum.html#how_vacuum_works
